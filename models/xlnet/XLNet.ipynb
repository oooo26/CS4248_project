{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEfSbAA4QHas",
        "outputId": "5681b091-8a34-4ff5-f669-c6e771c85545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NmMdkZO8R6q",
        "outputId": "9efcaf5a-16d0-44bd-b477-b30aba1c45ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (2.0.0+cu118)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (2022.10.31)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.107-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.10.7)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->pytorch-transformers) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->pytorch-transformers) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->pytorch-transformers) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.0.0->pytorch-transformers) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.0.0->pytorch-transformers) (3.25.2)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting botocore<1.30.0,>=1.29.107\n",
            "  Downloading botocore-1.29.107-py3-none-any.whl (10.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->pytorch-transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->pytorch-transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->pytorch-transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->pytorch-transformers) (3.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sacremoses->pytorch-transformers) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses->pytorch-transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses->pytorch-transformers) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore<1.30.0,>=1.29.107->boto3->pytorch-transformers) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.0.0->pytorch-transformers) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.0.0->pytorch-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=bdf20c84737d2388984e6d1bd2f55269d938f2616bc331d6a19c659fc37f778e\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, jmespath, botocore, s3transfer, boto3, pytorch-transformers\n",
            "Successfully installed boto3-1.26.107 botocore-1.29.107 jmespath-1.0.1 pytorch-transformers-1.2.0 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Keras-Preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from Keras-Preprocessing) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from Keras-Preprocessing) (1.22.4)\n",
            "Installing collected packages: Keras-Preprocessing\n",
            "Successfully installed Keras-Preprocessing-1.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.3 transformers-4.27.4\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-transformers\n",
        "!pip install Keras-Preprocessing\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ok002ceNB8E7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n",
        "from transformers import AdamW\n",
        "\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oYsV4H8fCpZ-",
        "outputId": "ecb3158b-b47d-4de8-a1d0-f7ff7bd162e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "DOpikSXbsvn-",
        "outputId": "655e4b5c-2368-4b70-a7ac-4d844b69d6b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8fb9aa8e-a276-4cb4-bd01-d89f3050bf34\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8fb9aa8e-a276-4cb4-bd01-d89f3050bf34\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving balancedtest.csv to balancedtest.csv\n",
            "Saving fulltrain.csv to fulltrain.csv\n"
          ]
        }
      ],
      "source": [
        "# Upload the train file from your local drive\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_UkeC7SG2krJ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"fulltrain.csv\", names = ['label', 'text'])\n",
        "test_df = pd.read_csv(\"balancedtest.csv\", names = ['label', 'text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UfxtwQy3axu",
        "outputId": "c6466dd9-046f-41b4-aea1-9cea8e335648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3000, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48854, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "print(test_df.shape)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2sPDL2qOTxSU"
      },
      "outputs": [],
      "source": [
        "# Create sentence and label lists\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "texts = df.text.values\n",
        "labels = df.label.values - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTwbInroL7kR",
        "outputId": "a5d07d7c-e6c1-45b9-c8bf-2f8198b1c53b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode\n",
        "import unidecode\n",
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuE5BqICAne2",
        "outputId": "fe541697-e348-40e4-f0fa-48f81394398a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "def preprocess_text(text_arr):\n",
        "    output_text = []\n",
        "    for x in text_arr:\n",
        "        processed = str(unidecode.unidecode(re.sub('[%s]' % re.escape(string.punctuation), '' , x))).lower()\n",
        "        sents = [s + \" [SEP] [CLS]\" for s in sent_tokenize(processed)]\n",
        "\n",
        "\n",
        "        output_text.append(' '.join(sents))\n",
        "        \n",
        "    return output_text\n",
        "sentences = preprocess_text(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "1353af10f04149fe83f1018fde062698",
            "0b5ef3cb0b7e46acaedcf7caca19d556",
            "f3b486baa27c4471baeab76c32df917a",
            "442d379dbc824f7dadf9c53c04472b23",
            "87995a7c3eed4b4aae3a7af2ebd7ac6a",
            "e0316cc21d5c4f2280bc23432f490ce5",
            "5b33bdab017e45ceaa3592927ed8ce73",
            "a5ede80fb34d49b1ad00d2d1842088f9",
            "47b93244df814febad88e637eb9d5eed",
            "95b09ebe4f67437dafa1117aa5cfd1e2",
            "49470edcc9f7419db24ef543fadf1975",
            "7dc20ba835f0474f88ac866e475b31fe",
            "5009870fd35b4528a7684aabce838da5",
            "ca83883a5f2b4c139703f467f8afd854",
            "de8ad2bdfef84fa4bfa70abe41bb75f8",
            "e0ad402adb3c48348a76af36606919c2",
            "a9494cfba2684f6da25093fdfe0dbe7f",
            "ed3a0593affe4af48cf7eb665cf01acb",
            "5abe428effd348978d03727a5967ee1c",
            "ee8e066a69f24fa6b6526504d5e00795",
            "38718a243c9d4c2cb94346b30f247bfe",
            "880191661a7941749eafed833e3a3238"
          ]
        },
        "id": "Z474sSC6oe7A",
        "outputId": "62bd75f4-ceb4-4105-d327-4f3243f48f67"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1353af10f04149fe83f1018fde062698"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dc20ba835f0474f88ac866e475b31fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['▁a', '▁little', '▁less', '▁than', '▁a', '▁decade', '▁ago', '▁hockey', '▁fans', '▁were', '▁blessed', '▁with', '▁a', '▁slate', '▁of', '▁games', '▁every', '▁night', '▁but', '▁on', '▁', 'th', 'ur', 's', 'day', '▁sources', '▁confirmed', '▁that', '▁for', '▁the', '▁ninth', '▁consecutive', '▁year', '▁', 'n', 'hl', '▁players', '▁have', '▁been', '▁locked', '▁out', '▁with', '▁very', '▁slim', '▁hopes', '▁of', '▁an', '▁agreement', '▁in', '▁sight', '▁it', '▁seems', '▁like', '▁just', '▁yesterday', '▁', 'mar', 'tin', '▁', 'st', '▁', 'lou', 'is', '▁and', '▁his', '▁lightning', '▁teammates', '▁were', '▁raising', '▁the', '▁', 'stan', 'ley', '▁cup', '▁high', '▁school', '▁hockey', '▁coach', '▁and', '▁one', 'time', '▁', 'es', 'p', 'n', '▁analyst', '▁bar', 'ry', '▁', 'mel', 'rose', '▁said', '▁obviously', '▁im', '▁still', '▁hoping', '▁the', '▁two', '▁sides', '▁can', '▁come', '▁together', '▁and', '▁reach', '▁an', '▁agreement', '▁but', '▁im', '▁starting', '▁to', '▁think', '▁nobody', '▁really', '▁misses', '▁hockey', '▁anymore', '▁no', 'pe', '▁nobody', '▁but', '▁old', '▁bar', 'ry', '▁', 'id', '▁still', '▁love', '▁to', '▁catch', '▁an', '▁at', 'lan', 'ta', '▁', 'th', 'rash', 'ers', '▁game', '▁observers', '▁have', '▁noted', '▁that', '▁when', '▁arena', '▁doors', '▁do', '▁reopen', '▁the', '▁', 'n', 'hl', '▁will', '▁face', '▁the', '▁perhaps', '▁greater', '▁challenge', '▁of', '▁convincing', '▁fans', '▁to', '▁return', '▁to', '▁hockey', '▁instead', '▁of', '▁watching', '▁more', '▁popular', '▁sports', '▁like', '▁football', '▁basketball', '▁baseball', '▁and', '▁slam', 'ball', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']'], ['▁the', '▁writers', '▁of', '▁the', '▁', 'h', 'bo', '▁series', '▁the', '▁so', 'pra', 'no', 's', '▁took', '▁another', '▁daring', '▁storytelling', '▁step', '▁by', '▁killing', '▁off', '▁10', '▁million', '▁fans', '▁during', '▁the', '▁seventh', '▁seasons', '▁premiere', '▁episode', '▁sun', 'day', '▁night', '▁this', '▁was', '▁definitely', '▁a', '▁bold', '▁choice', '▁one', '▁that', '▁producers', '▁of', '▁the', '▁show', '▁would', '▁have', '▁never', '▁thought', '▁of', '▁making', '▁five', '▁years', '▁ago', '▁said', '▁new', '▁york', '▁times', '▁television', '▁critic', '▁', 'virginia', '▁he', 'ffer', 'nan', '▁who', '▁noted', '▁that', '▁the', '▁move', '▁was', '▁hinted', '▁at', '▁in', '▁a', '▁season', 'five', '▁episode', '▁in', '▁which', '▁to', 'ny', '▁dream', 't', '▁he', '▁was', '▁riding', '▁a', '▁horse', '▁through', '▁his', '▁house', '▁but', '▁now', '▁that', '▁', 'i', '▁look', '▁back', '▁this', '▁was', '▁strongly', '▁for', 'es', 'had', 'owed', '▁throughout', '▁all', '▁of', '▁last', '▁season', '▁industry', '▁insider', 's', '▁predicted', '▁that', '▁the', '▁shows', '▁producers', '▁would', '▁try', '▁to', '▁bring', '▁at', '▁least', '▁some', '▁fans', '▁back', '▁for', '▁the', '▁series', '▁finale', '▁which', '▁may', '▁come', '▁as', '▁early', '▁as', '▁may', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']'], ['▁despite', '▁claims', '▁from', '▁the', '▁', 'tv', '▁news', '▁outlet', '▁to', '▁offer', '▁nonstop', '▁news', '▁and', '▁coverage', '▁you', '▁can', '▁count', '▁on', '▁an', '▁self', 'news', '▁investigation', '▁has', '▁uncovered', '▁hundreds', '▁of', '▁instances', '▁in', '▁which', '▁', 'ka', 'm', 'r', '▁channel', '▁4', '▁10', '▁', 'o', 'clock', '▁eyewitness', '▁news', '▁team', '▁relied', '▁almost', '▁exclusively', '▁on', '▁news', '▁reports', '▁weather', '▁forecasts', '▁and', '▁even', '▁special', 'interest', '▁features', '▁already', '▁generated', '▁by', '▁the', '▁stations', '▁6', '▁', 'o', 'clock', '▁eyewitness', '▁news', '▁team', '▁the', '▁investigation', '▁found', '▁that', '▁10', '▁', 'o', 'clock', '▁news', '▁team', '▁is', '▁in', '▁fact', '▁not', '▁the', '▁team', '▁you', '▁can', '▁trust', '▁in', '▁an', '▁examination', '▁of', '▁98', '▁consecutive', '▁prime', 'time', '▁and', '▁late', 'night', '▁broadcasts', '▁including', '▁dozens', '▁more', '▁nationwide', '▁the', '▁a', 'mar', 'illo', 'based', '▁station', 'the', '▁regions', '▁self', 'styled', '▁news', '▁leader', 're', 'pe', 'ated', 'ly', '▁ran', '▁pieces', '▁for', '▁its', '▁health', '▁beat', '▁pet', '▁patrol', '▁and', '▁bargain', '▁', 'buster', 's', '▁segments', '▁in', '▁both', '▁evening', '▁news', '▁slots', '▁and', '▁regularly', '▁relay', 'ed', '▁the', '▁same', '▁weather', '▁updates', '▁and', '▁traffic', '▁reports', '▁up', '▁to', '▁15', '▁times', '▁a', '▁day', '▁', 'ka', 'm', 'r', '▁even', '▁routinely', '▁', 're', 'ha', 'shed', '▁6', '▁pm', '▁footage', '▁for', '▁seemingly', '▁urgent', '▁breaking', '▁news', '▁reports', '▁most', '▁recently', '▁the', '▁plum', '▁creek', '▁nursing', '▁home', '▁power', '▁out', 'age', '▁and', '▁the', '▁', 'bon', 'ham', '▁middle', '▁school', '▁roof', '▁collapse', '▁in', '▁an', '▁a', 'pri', 'l', '▁incident', '▁involving', '▁the', '▁10', '▁pm', '▁', 're', 'cap', '▁of', '▁a', '▁local', '▁cancer', '▁fun', '▁run', '▁anchor', '▁and', 'y', '▁just', 'us', '▁read', '▁almost', '▁the', '▁exact', '▁same', '▁copy', '▁introducing', '▁the', '▁piece', '▁as', '▁he', '▁had', '▁just', '▁four', '▁hours', '▁earlier', '▁while', '▁reporter', '▁', 'sha', 'land', 'y', 's', '▁and', 'erson', '▁altered', '▁only', '▁one', '▁word', '▁between', '▁broadcasts', '▁changing', '▁heart', 'war', 'ming', '▁to', '▁in', 'spir', 'ing', '▁if', '▁they', 're', '▁on', '▁our', '▁side', '▁as', '▁they', '▁claim', '▁what', '▁then', '▁is', '▁a', '▁purported', 'ly', '▁professional', '▁news', '▁team', '▁doing', '▁in', '▁the', '▁four', '▁hours', '▁between', '▁broadcasts', '▁a', 'mar', 'illo', '▁resident', '▁and', '▁frequent', '▁local', 'news', '▁viewer', '▁mark', '▁jet', 'te', '▁said', '▁during', '▁another', '▁10', '▁pm', '▁broadcast', '▁live', '▁continuing', '▁coverage', '▁from', '▁reporter', '▁mat', 't', '▁or', 'land', 'o', '▁of', '▁a', '▁two', 'al', 'arm', '▁', 'el', 'wood', '▁park', '▁house', '▁fire', '▁consisted', '▁almost', '▁wholly', '▁of', '▁previously', '▁aired', '▁footage', '▁of', '▁the', '▁firefighters', '▁in', '▁action', '▁the', '▁lack', '▁of', '▁updated', '▁footage', '▁disappointed', '▁viewers', '▁such', '▁as', '▁here', 'ford', '▁tx', 's', '▁', 'kel', 'ly', '▁by', 'er', '▁whose', '▁mild', '▁curiosity', '▁about', '▁the', '▁blaze', '▁first', '▁p', 'ique', 'd', '▁at', '▁the', '▁6', '▁pm', '▁newscast', '▁went', '▁un', 'grat', 'ified', '▁', 'h', '3', 'well', '▁continue', '▁to', '▁watch', '▁this', '▁important', '▁breaking', '▁news', '▁story', 'h', '3', 'pel', 'iza', 'be', 'th', '▁', 'din', 'h', '▁after', '▁a', '▁report', '▁on', '▁a', '▁broken', '▁gas', '▁main', '▁which', '▁had', '▁already', '▁run', '▁in', '▁two', '▁previous', '▁newscast', 'sp', '▁its', '▁true', '▁that', '▁the', '▁image', '▁of', '▁that', '▁', 's', 'cor', 'ched', '▁little', '▁doll', '▁was', '▁powerful', '▁and', '▁may', '▁have', '▁bore', '▁repeating', '▁but', '▁where', '▁was', '▁the', '▁follow', 'up', '▁footage', '▁of', '▁the', '▁devastated', '▁family', '▁at', '▁a', '▁red', '▁cross', '▁shelter', '▁by', 'er', '▁said', '▁or', '▁some', '▁fresh', '▁', 'bro', 'll', '▁of', '▁the', '▁charred', '▁ruins', '▁of', '▁the', '▁house', '▁the', '▁public', '▁deserves', '▁better', '▁the', '▁investigation', '▁also', '▁found', '▁the', '▁10', '▁pm', '▁', 'ka', 'm', 'r', '▁broadcast', '▁consistently', '▁', 're', 'air', 'ed', '▁closing', '▁stock', '▁numbers', '▁and', '▁high', 'school', '▁baseball', '▁highlights', '▁and', '▁sports', '▁', 'blo', 'oper', 's', '▁its', '▁producers', '▁and', '▁anchor', 's', '▁apparently', '▁unaware', '▁or', '▁in', 'different', '▁to', '▁the', '▁fact', '▁that', '▁the', '▁information', '▁was', '▁hours', '▁old', '▁and', '▁already', '▁common', '▁knowledge', '▁among', '▁viewers', '▁they', '▁say', '▁that', '▁the', '▁6', '▁', 'o', 'clock', '▁news', '▁team', '▁is', '▁the', '▁areas', '▁most', '▁watched', '▁news', '▁team', '▁jet', 'te', '▁said', '▁especially', '▁by', '▁the', '▁10', '▁', 'o', 'clock', '▁news', '▁team', '▁just', '▁last', '▁', 'tu', 'es', 'day', '▁investigative', '▁reporter', '▁me', 'a', 'ghan', '▁coll', 'ier', 's', '▁problem', '▁solve', 'rs', '▁segment', '▁on', '▁', 's', 'qual', 'id', '▁conditions', '▁at', '▁a', '▁local', '▁dog', '▁', 'ken', 'nel', '▁aired', '▁again', '▁at', '▁10', '▁pm', '▁without', '▁even', '▁a', '▁cursor', 'y', '▁update', '▁on', '▁the', '▁broken', 'legged', '▁puppy', '▁featured', '▁in', '▁the', '▁report', '▁their', '▁', 's', 'cor', 'ching', '▁summer', '▁coverage', '▁was', '▁even', '▁worse', '▁jet', 'te', '▁continued', '▁how', '▁many', '▁times', '▁do', '▁you', '▁have', '▁to', '▁repeat', '▁the', '▁same', '▁cool', '▁tips', '▁before', '▁all', '▁of', '▁a', 'mar', 'illo', '▁is', '▁crystal', '▁clear', '▁on', '▁exactly', '▁how', '▁to', '▁beat', '▁the', '▁heat', '▁while', '▁', 'ka', 'm', 'r', '▁was', '▁a', '▁particularly', '▁flag', 'rant', '▁offender', '▁it', '▁is', '▁by', '▁no', '▁means', '▁alone', '▁in', '▁a', '▁segment', '▁about', '▁the', '▁', 'san', '▁die', 'go', '▁zoo', 's', '▁baby', '▁panda', 's', '▁', 'k', 'f', 'mb', '▁', 'tv', '8', 's', '▁news', '▁at', '▁11', '▁not', '▁only', '▁offered', '▁footage', '▁identical', '▁to', '▁the', '▁previous', '▁telecast', '▁but', '▁practically', '▁in', 'distinguishable', '▁co', 'os', '▁of', '▁affection', '▁from', '▁the', '▁co', 'an', 'chor', '▁at', '▁some', '▁stations', '▁the', '▁problem', '▁goes', '▁far', '▁beyond', '▁one', 'time', '▁reuse', '▁an', '▁11', '▁pm', '▁segment', '▁on', '▁heart', 'smart', '▁dinner', '▁alternatives', '▁on', '▁new', '▁haven', '▁', 'connecticut', 's', '▁', 'w', 't', 'nh', '▁channel', '▁8', '▁was', '▁not', '▁only', '▁previously', '▁seen', '▁on', '▁the', '▁6', '▁pm', '▁news', '▁but', '▁also', '▁on', '▁live', '▁at', '▁5', '▁the', '▁4', '▁report', '▁and', '▁the', '▁news', '▁at', '▁noon', '▁with', '▁', 's', 'onia', '▁bag', 'h', 'da', 'dy', '▁another', '▁piece', '▁on', '▁the', '▁city', 's', '▁aging', '▁school', '▁buses', '▁was', '▁rotate', 'd', '▁into', '▁the', '▁following', '▁days', '▁good', '▁morning', '▁new', '▁haven', '▁as', '▁well', '▁in', '▁extreme', '▁examples', '▁such', '▁as', '▁in', '▁', 'lou', 'is', 'ville', '▁', 'ky', 's', '▁', 'wl', 'ky', 'tv', '▁prime', 'time', '▁and', '▁late', 'night', '▁newscast', 's', '▁the', '▁only', '▁', 'distinguishable', '▁characteristic', '▁is', '▁the', '▁lead', '▁anchor', 's', '▁concluding', '▁suggestion', '▁to', '▁stay', '▁tune', 'd', '▁for', '▁da', 'vid', '▁letter', 'man', 's', '▁the', '▁late', '▁show', '▁despite', '▁the', '▁mounting', '▁controversy', '▁over', '▁the', '▁', 'ka', 'm', 'r', '▁channel', '▁4', '▁team', '▁the', '▁investigation', '▁was', '▁unable', '▁to', '▁conclusive', 'ly', '▁prove', '▁that', '▁the', '▁hopeful', '▁wishes', '▁to', '▁see', '▁viewers', '▁the', '▁next', '▁day', '▁and', '▁the', '▁ca', 'mara', 'der', 'ie', '▁and', '▁laughter', '▁shared', '▁between', '▁co', 'an', 'chor', 's', '▁', 'ky', 'la', '▁', 'cul', 'lin', 'ane', '▁and', '▁', 'el', 'iza', 'be', 'th', '▁', 'din', 'h', '▁were', '▁anything', '▁less', '▁than', '▁genuine', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']'], ['▁after', '▁receiving', '▁sub', 'par', '▁service', '▁and', '▁experiencing', '▁an', '▁unusually', '▁long', '▁wait', '▁for', '▁his', '▁4', '75', '▁lunch', '▁at', '▁a', '▁local', '▁beef', 'side', '▁family', '▁restaurant', '▁', 'mon', 'day', '▁customer', '▁', 'gus', '▁', 'o', 'con', 'nor', '▁opted', '▁to', '▁give', '▁waitress', '▁car', 'la', '▁', 'hy', 'am', 's', '▁a', '▁reduced', '▁10', '▁percent', '▁tip', '▁in', '▁an', '▁attempt', '▁to', '▁communicate', '▁his', '▁dissatisfaction', '▁and', '▁raise', '▁awareness', '▁of', '▁the', '▁areas', '▁in', '▁which', '▁he', '▁felt', '▁her', '▁performance', '▁was', '▁lacking', '▁', 'o', 'con', 'nor', '▁hoped', '▁his', '▁reduced', '▁tip', '▁would', '▁be', '▁a', '▁wake', 'up', '▁call', '▁for', '▁', 'hy', 'am', 's', '▁', 'hy', 'am', 's', '▁49', '▁who', '▁has', '▁been', '▁serving', '▁tables', '▁at', '▁the', '▁popular', '▁eat', 'ery', '▁for', '▁13', '▁years', '▁expressed', '▁enthusiastic', '▁gratitude', '▁for', '▁the', '▁immense', '▁personal', '▁growth', '▁the', '▁gesture', '▁will', '▁afford', '▁her', '▁adding', '▁that', '▁in', '▁the', '▁long', '▁run', '▁the', '▁experience', '▁will', '▁make', '▁her', '▁a', '▁better', '▁waitress', '▁maybe', '▁', 'i', '▁was', '▁a', '▁little', '▁short', '▁with', '▁him', '▁when', '▁', 'i', '▁told', '▁him', '▁to', '▁hold', '▁on', '▁a', '▁', 'sec', '▁but', '▁in', '▁the', '▁future', '▁ill', '▁do', '▁my', '▁best', '▁to', '▁ensure', '▁a', '▁situation', '▁like', '▁that', '▁never', '▁ever', '▁happens', '▁again', '▁said', '▁', 'hy', 'am', 's', '▁who', '▁put', '▁', 'o', 'con', 'nor', 's', '▁order', '▁slip', '▁in', '▁as', '▁the', '▁under', 'staff', 'ed', '▁cook', 's', '▁dealt', '▁with', '▁a', '▁large', '▁complicated', '▁meal', '▁for', '▁a', '▁bus', 'load', '▁of', '▁senior', 'citizen', '▁tourists', '▁its', '▁days', '▁like', '▁this', '▁that', '▁', 'i', '▁thank', '▁god', '▁', 'i', '▁get', '▁paid', '▁less', '▁than', '▁minimum', '▁wage', '▁and', '▁can', '▁rely', '▁on', '▁a', '▁built', 'in', '▁economic', '▁incentive', '▁to', '▁keep', '▁me', '▁motivated', '▁during', '▁those', '▁16', 'hour', '▁double', '▁shifts', '▁', 'hy', 'am', 's', '▁added', '▁that', '▁she', '▁now', '▁knows', '▁she', '▁should', '▁always', '▁bring', '▁a', '▁glass', '▁of', '▁water', '▁without', '▁any', '▁ice', '▁cubes', '▁every', '▁time', '▁someone', '▁orders', '▁a', '▁diet', '▁co', 'ke', '▁and', '▁that', '▁the', '▁phrase', '▁when', '▁you', '▁get', '▁a', '▁minute', '▁is', '▁in', '▁fact', '▁a', '▁polite', '▁way', '▁of', '▁indicating', '▁that', '▁the', '▁customer', '▁wants', '▁his', '▁request', '▁filled', '▁in', '▁under', '▁one', '▁minute', '▁if', '▁he', '▁hadn', 't', '▁with', 'held', '▁that', '▁50', '▁cents', '▁', 'id', '▁make', '▁these', '▁same', '▁mistakes', '▁over', '▁and', '▁over', '▁for', '▁the', '▁rest', '▁of', '▁my', '▁career', '▁she', '▁said', '▁even', '▁at', '▁my', '▁age', '▁its', '▁amazing', '▁to', '▁think', '▁you', '▁can', '▁still', '▁learn', '▁something', '▁new', '▁about', '▁a', '▁low', 'paying', '▁men', 'ial', 'labor', '▁job', '▁', 'hy', 'am', 's', '▁added', '▁that', '▁the', '▁next', '▁time', '▁she', '▁sees', '▁', 'o', 'con', 'nor', '▁she', '▁will', '▁remember', '▁that', '▁he', '▁under', 't', 'ipped', '▁her', '▁and', '▁strive', '▁to', '▁serve', '▁him', '▁better', '▁to', '▁avoid', '▁any', '▁further', '▁disappointment', '▁', 'o', 'con', 'nor', '▁he', '▁may', '▁not', '▁realize', '▁it', '▁but', '▁his', '▁actions', '▁today', '▁will', '▁not', '▁only', '▁improve', '▁my', '▁work', '▁ethic', '▁but', '▁will', '▁directly', '▁benefit', '▁him', '▁as', '▁well', '▁in', '▁that', '▁', 'i', '▁will', '▁gain', '▁economic', '▁and', '▁personal', '▁rewards', '▁by', '▁treating', '▁him', '▁with', '▁the', '▁tremendous', '▁respect', '▁and', '▁un', 'fail', 'ing', '▁attention', '▁he', '▁deserves', '▁', 'hy', 'am', 's', '▁said', '▁so', '▁really', '▁if', '▁you', '▁think', '▁about', '▁it', '▁that', '▁10', '▁percent', '▁tip', '▁is', '▁a', '▁win', 'win', '▁situation', '▁for', '▁both', '▁of', '▁us', '▁', 'o', 'con', 'nor', '▁said', '▁he', '▁felt', '▁he', '▁needed', '▁to', '▁get', '▁through', '▁to', '▁the', '▁waitress', '▁and', '▁did', '▁so', '▁the', '▁best', '▁way', '▁he', '▁knew', '▁how', '▁by', '▁giving', '▁her', '▁less', '▁than', '▁the', '▁universally', '▁agreed', 'upon', '▁minimum', '▁', 'i', '▁sent', '▁a', '▁clear', '▁unmistakable', '▁yet', '▁constructive', '▁message', '▁said', '▁', 'o', 'con', 'nor', '▁who', '▁claimed', '▁that', '▁he', '▁hoped', '▁the', '▁smaller', '▁tip', '▁would', '▁be', '▁a', '▁wake', 'up', '▁call', '▁for', '▁', 'hy', 'am', 's', '▁', 'i', '▁was', '▁just', '▁trying', '▁to', '▁help', '▁push', '▁car', 'la', '▁along', '▁the', '▁path', '▁to', '▁achieving', '▁her', '▁full', '▁potential', '▁as', '▁an', '▁employee', '▁it', '▁was', '▁the', '▁absolute', '▁least', '▁', 'i', '▁could', '▁do', '▁he', '▁added', '▁', 'o', 'con', 'nor', '▁said', '▁he', '▁first', '▁considered', '▁reducing', '▁his', '▁usual', '▁15', '▁percent', '▁tip', '▁for', '▁the', '▁waitress', '▁when', '▁', 'hy', 'am', 's', '▁failed', '▁to', '▁replace', '▁the', '▁cream', '▁packet', 's', '▁for', '▁his', '▁coffee', '▁while', '▁he', '▁looked', '▁over', '▁the', '▁restaurants', '▁extensive', '▁list', '▁of', '▁lunch', '▁special', 's', '▁but', '▁it', '▁wasn', 't', '▁until', '▁', 'hy', 'am', 's', '▁neglected', '▁to', '▁ask', '▁if', '▁he', '▁needed', '▁extra', '▁', 'ke', 'tch', 'up', '▁that', '▁', 'o', 'con', 'nor', '▁made', '▁the', '▁decision', '▁to', '▁let', '▁his', '▁money', '▁do', '▁the', '▁talking', '▁in', '▁the', '▁competitive', '▁service', '▁industry', '▁there', '▁is', '▁a', '▁mechanism', '▁to', '▁effect', '▁change', '▁he', '▁said', '▁', 'i', '▁know', '▁this', '▁will', '▁be', '▁an', '▁invaluable', '▁lesson', '▁she', '▁won', 't', '▁soon', '▁forget', '▁but', '▁', 'i', '▁just', '▁did', '▁what', '▁any', '▁decent', '▁human', '▁being', '▁in', '▁my', '▁position', '▁would', '▁have', '▁done', '▁and', '▁that', '▁feels', '▁good', '▁', 'o', 'con', 'nor', '▁said', '▁his', '▁overall', '▁goal', '▁was', '▁not', '▁only', '▁to', '▁receive', '▁better', '▁service', '▁but', '▁to', '▁help', '▁', 'hy', 'am', 's', '▁become', '▁a', '▁role', '▁model', '▁for', '▁her', '▁two', '▁teenage', '▁children', '▁', 'ty', 'ler', '▁and', '▁mi', 'cha', 'el', '▁', 'i', '▁know', '▁as', '▁well', '▁as', '▁anyone', '▁how', '▁hard', '▁it', '▁is', '▁for', '▁a', '▁single', '▁mother', '▁with', '▁a', '▁limited', '▁income', '▁to', '▁raise', '▁kids', '▁on', '▁her', '▁own', '▁he', '▁said', '▁but', '▁this', '▁way', '▁they', '▁learn', '▁the', '▁value', '▁of', '▁money', '▁and', '▁the', '▁satisfaction', '▁of', '▁a', '▁job', '▁well', '▁done', '▁in', '▁the', '▁end', '▁', 'hy', 'am', 's', '▁said', '▁she', '▁could', '▁not', '▁agree', '▁more', '▁my', '▁boys', '▁have', '▁had', '▁a', '▁few', '▁run', 'ins', '▁with', '▁the', '▁law', '▁and', '▁they', '▁could', '▁certainly', '▁use', '▁some', '▁good', '▁advice', '▁she', '▁said', '▁', 'i', '▁can', 't', '▁wait', '▁for', '▁them', '▁and', '▁maybe', '▁a', '▁couple', '▁of', '▁their', '▁friends', '▁to', '▁meet', '▁', 'm', 'r', '▁', 'o', 'con', 'nor', '▁first', 'hand', '▁', 'i', '▁think', '▁they', 'd', '▁get', '▁a', '▁lot', '▁out', '▁of', '▁it', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']'], ['▁after', '▁watching', '▁his', '▁beloved', '▁seat', 'tle', '▁marine', 'rs', '▁prevail', '▁against', '▁the', '▁', 'san', '▁die', 'go', '▁pad', 're', 's', '▁third', 'grader', '▁', 'tim', 'my', '▁has', 'ter', 't', '▁was', '▁moved', '▁to', '▁ask', '▁his', '▁father', '▁46', 'year', 'old', '▁insurance', '▁salesman', '▁', 'christ', 'oph', 'er', '▁has', 'ter', 't', '▁why', '▁inter', 'league', '▁play', '▁is', '▁good', '▁well', '▁it', '▁lets', '▁people', '▁see', '▁the', '▁teams', '▁they', '▁normally', '▁don', 't', '▁get', '▁to', '▁see', '▁all', '▁that', '▁often', '▁', 'i', '▁think', '▁is', '▁the', '▁point', '▁there', '▁buddy', '▁has', 'ter', 't', '▁said', '▁after', '▁beginning', '▁three', '▁different', '▁sentences', '▁in', '▁seven', '▁minutes', '▁after', '▁all', '▁without', '▁inter', 'league', '▁play', '▁we', '▁wouldn', 't', '▁get', '▁to', '▁see', '▁players', '▁like', '▁like', '▁', 'bri', 'an', '▁', 'gil', 'es', '▁and', '▁', 's', 'cott', '▁line', 'b', 'rink', '▁would', '▁we', '▁although', '▁', 'i', '▁think', '▁we', '▁play', '▁the', '▁yank', 'ees', '▁and', '▁red', '▁so', 'x', '▁less', '▁often', '▁as', '▁a', '▁result', '▁right', '▁yeah', '▁im', '▁pretty', '▁sure', '▁that', 's', '▁how', '▁they', '▁do', '▁it', '▁in', '▁a', '▁moving', '▁but', '▁ultimately', '▁doomed', '▁effort', '▁to', '▁give', '▁his', '▁impression', 'able', '▁boy', '▁the', '▁right', '▁messages', '▁', 'christ', 'oph', 'er', '▁also', '▁attempted', '▁to', '▁answer', '▁', 'tim', 'my', 's', '▁questions', '▁regarding', '▁why', '▁only', '▁the', '▁', 'american', '▁league', '▁has', '▁a', '▁', 'dh', '▁why', '▁and', '▁how', '▁the', '▁all', 'star', '▁game', '▁now', '▁counts', '▁what', '▁performance', 'enhancing', '▁drugs', '▁are', '▁and', '▁how', '▁baseball', '▁officials', '▁could', '▁have', '▁sat', '▁', 'id', 'ly', '▁by', '▁when', '▁they', '▁knew', '▁there', '▁was', '▁a', '▁major', '▁steroid', '▁problem', '▁in', '▁their', '▁sport', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']'], ['▁at', '▁a', '▁cafeteria', 'table', '▁press', '▁conference', '▁', 'mon', 'day', '▁da', 'vid', '▁per', 'nell', '▁10', '▁categori', 'cal', 'ly', '▁denied', '▁girl', 'lik', 'ing', '▁allegations', '▁recently', '▁levied', '▁against', '▁him', '▁by', '▁fellow', '▁lake', 'view', '▁elementary', '▁school', '▁fourth', 'grader', '▁', 'jo', 'na', 'than', '▁', 'witt', '▁', 'i', '▁do', '▁not', '▁have', '▁not', '▁and', '▁will', '▁not', '▁ever', '▁like', '▁girls', '▁per', 'nell', '▁told', '▁the', '▁crowd', '▁of', '▁seven', '▁boys', '▁assembled', '▁at', '▁the', '▁lunch', 'room', 's', '▁back', '▁table', '▁', 'm', 'r', '▁', 'witt', 's', '▁accusations', '▁are', '▁not', '▁only', '▁100', '▁percent', '▁false', '▁but', '▁also', '▁', 's', 'lander', 'ous', '▁as', '▁it', '▁has', '▁always', '▁been', '▁my', '▁firm', '▁conviction', '▁that', '▁girls', '▁are', '▁totally', '▁and', '▁completely', '▁gross', '▁per', 'nell', '▁went', '▁on', '▁to', '▁suggest', '▁that', '▁perhaps', '▁it', '▁is', '▁', 'witt', '▁who', '▁like', 's', '▁girls', '▁particularly', '▁', 'je', 'nny', '▁', 'lough', 'lin', '▁10', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']'], ['▁stunned', '▁shock', '▁and', '▁dismay', '▁were', '▁just', '▁a', '▁few', '▁of', '▁the', '▁reactions', '▁from', '▁bob', 'by', '▁gun', 'ter', 'grass', '▁on', '▁', 'tu', 'es', 'day', '▁when', '▁the', '▁10', 'year', 'old', '▁learned', '▁that', '▁the', '▁woman', '▁from', '▁the', '▁', 'guin', 'ness', '▁book', '▁of', '▁world', '▁records', '▁who', '▁has', '▁the', '▁ability', '▁to', '▁pop', '▁her', '▁', 'bul', 'ging', '▁eye', 'ball', 's', '▁nearly', '▁all', '▁the', '▁way', '▁out', '▁of', '▁their', '▁socket', 's', '▁was', '▁not', '▁a', '▁million', 'aire', '▁no', '▁way', '▁she', 's', '▁gotta', '▁to', '▁be', '▁rich', '▁said', '▁gun', 'ter', 'grass', '▁adding', '▁that', '▁if', '▁he', '▁himself', '▁possessed', '▁the', '▁woman', 's', '▁unique', '▁attribute', '▁he', '▁would', '▁be', '▁a', '▁billionaire', '▁maybe', '▁she', '▁spent', '▁it', '▁all', '▁on', '▁a', '▁giant', '▁house', '▁yeah', '▁that', '▁makes', '▁sense', '▁she', '▁probably', '▁bought', '▁a', '▁huge', '▁mansion', '▁at', '▁press', '▁time', '▁gun', 'ter', 'grass', '▁had', '▁reportedly', '▁grown', '▁even', '▁more', '▁disillusioned', '▁after', '▁learning', '▁that', '▁the', '▁man', '▁who', '▁holds', '▁the', '▁record', '▁for', '▁the', '▁world', 's', '▁longest', '▁fingernails', '▁lives', '▁in', '▁a', '▁developing', '▁nation', '▁and', '▁has', '▁no', '▁access', '▁to', '▁clean', '▁water', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']'], ['▁speaking', '▁with', '▁reporters', '▁before', '▁a', '▁game', '▁', 'mon', 'day', '▁local', '▁little', '▁league', 'r', '▁', 'na', 'than', '▁', 'gar', 'r', 'ett', '▁expressed', '▁his', '▁heartfelt', '▁wish', '▁that', '▁just', '▁once', '▁his', '▁unemployed', '▁father', '▁could', '▁not', '▁make', '▁it', '▁out', '▁to', '▁see', '▁him', '▁play', '▁every', '▁time', '▁', 'i', '▁come', '▁up', '▁to', '▁bat', '▁', 'i', '▁hope', '▁deep', '▁down', '▁inside', '▁that', '▁this', '▁will', '▁be', '▁the', '▁time', '▁that', '▁', 'i', '▁look', '▁up', '▁into', '▁the', '▁stands', '▁and', '▁don', 't', '▁see', '▁my', '▁dad', '▁said', '▁the', '▁visibly', '▁down', 'cast', '▁10', 'year', 'old', '▁confirming', '▁that', '▁his', '▁father', '▁pet', 'er', '▁', 'gar', 'r', 'ett', '▁a', '▁former', '▁hospital', '▁records', '▁clerk', '▁who', '▁has', '▁been', '▁out', '▁of', '▁work', '▁for', '▁15', '▁months', '▁had', '▁not', '▁missed', '▁even', '▁one', '▁game', '▁all', '▁season', '▁', 'i', '▁look', '▁down', '▁the', '▁rows', '▁of', '▁bleach', 'ers', '▁but', '▁he', 's', '▁always', '▁there', '▁and', '▁when', '▁', 'i', '▁see', '▁him', '▁my', '▁heart', '▁just', '▁sink', 's', '▁', 'i', '▁would', '▁give', '▁anything', '▁for', '▁him', '▁to', '▁be', '▁in', '▁an', '▁office', '▁not', '▁watching', '▁me', '▁play', '▁', 'gar', 'r', 'ett', '▁added', '▁the', '▁fourth', 'grader', '▁admitted', '▁he', '▁often', '▁feels', '▁', 'en', 'vi', 'ous', '▁of', '▁his', '▁teammates', '▁whose', '▁steadily', '▁employed', '▁father', 's', '▁are', '▁either', '▁unable', '▁to', '▁make', '▁it', '▁to', '▁games', '▁or', '▁only', '▁show', '▁up', '▁for', '▁the', '▁final', '▁inning', '▁or', '▁two', '▁in', '▁addition', '▁', 'gar', 'r', 'ett', '▁reported', '▁being', '▁especially', '▁saddened', '▁when', '▁his', '▁dad', '▁failed', '▁to', '▁miss', '▁even', '▁the', '▁most', '▁inconvenient', 'ly', '▁time', 'd', '▁games', '▁right', '▁after', '▁school', '▁in', '▁the', '▁middle', '▁of', '▁the', '▁week', '▁stating', '▁that', '▁he', '▁felt', '▁embarrassed', '▁and', '▁ashamed', '▁that', '▁everyone', '▁else', '▁on', '▁the', '▁team', '▁might', '▁notice', '▁that', '▁his', '▁father', '▁was', '▁the', '▁only', '▁parent', '▁in', '▁the', '▁stands', '▁with', '▁his', '▁father', '▁never', '▁putting', '▁in', '▁long', '▁hours', '▁at', '▁work', '▁', 'gar', 'r', 'ett', '▁acknowledged', '▁that', '▁he', '▁has', '▁devised', '▁ways', '▁to', '▁help', '▁him', '▁cope', '▁with', '▁the', '▁constant', '▁attention', '▁he', '▁receives', '▁', 'i', '▁try', '▁to', '▁put', '▁the', '▁whole', '▁thing', '▁out', '▁of', '▁my', '▁mind', '▁but', '▁sometimes', '▁its', '▁really', '▁hard', '▁not', '▁to', '▁think', '▁about', '▁how', '▁dad', '▁isn', 't', '▁stuck', '▁behind', '▁a', '▁desk', '▁somewhere', '▁especially', '▁when', '▁he', '▁stands', '▁up', '▁and', '▁cheer', 's', '▁my', '▁name', '▁said', '▁', 'gar', 'r', 'ett', '▁', 's', 'ul', 'len', 'ly', '▁noting', '▁that', '▁the', '▁number', '▁of', '▁games', '▁left', '▁in', '▁the', '▁season', '▁that', '▁his', '▁father', '▁could', '▁potentially', '▁miss', '▁were', '▁rapidly', '▁running', '▁out', '▁and', '▁once', '▁', 'i', '▁start', '▁thinking', '▁about', '▁how', '▁he', '▁came', '▁to', '▁yet', '▁another', '▁game', '▁and', '▁how', '▁hell', '▁probably', '▁come', '▁to', '▁the', '▁next', '▁one', '▁too', '▁', 'i', '▁just', '▁feel', '▁awful', '▁', 'i', '▁guess', '▁dad', '▁will', '▁always', '▁be', '▁the', '▁one', '▁wh', 'ist', 'ling', '▁and', '▁clap', 'ping', '▁for', '▁me', '▁in', '▁the', '▁stands', '▁instead', '▁of', '▁further', 'ing', '▁a', '▁career', '▁', 'gar', 'r', 'ett', '▁continued', '▁and', '▁that', 's', '▁just', '▁something', '▁', 'i', '▁have', '▁to', '▁live', '▁with', '▁in', '▁addition', '▁to', '▁showing', '▁up', '▁at', '▁games', '▁', 'gar', 'r', 'ett', 's', '▁long', 'un', 'employed', '▁father', '▁is', '▁said', '▁to', '▁frequently', '▁disappoint', '▁his', '▁son', '▁with', '▁his', '▁constant', '▁availability', '▁at', '▁home', '▁as', '▁well', '▁in', '▁particular', '▁', 'gar', 'r', 'ett', '▁stated', '▁that', '▁his', '▁dad', '▁who', '▁hasn', 't', '▁had', '▁a', '▁job', '▁interview', '▁in', '▁months', '▁is', '▁always', '▁ready', '▁to', '▁play', '▁catch', '▁in', '▁the', '▁backyard', '▁at', '▁any', '▁time', '▁drive', '▁him', '▁to', '▁and', '▁from', '▁practice', '▁at', '▁all', '▁hours', '▁and', '▁even', '▁help', '▁out', '▁with', '▁school', '▁or', '▁boy', '▁scout', 's', '▁projects', '▁more', 'over', '▁', 'gar', 'r', 'ett', '▁noted', '▁with', '▁a', '▁de', 'ject', 'ed', '▁sigh', '▁that', '▁his', '▁father', '▁frequently', '▁offers', '▁to', '▁take', '▁him', '▁to', '▁the', '▁local', '▁minor', '▁league', '▁ballpark', '▁in', '▁spite', '▁of', '▁his', '▁frustration', 's', '▁with', '▁his', '▁father', 's', '▁behavior', '▁', 'gar', 'r', 'ett', '▁said', '▁that', '▁ever', '▁since', '▁he', '▁joined', '▁little', '▁league', '▁last', '▁spring', 'short', 'ly', '▁after', '▁his', '▁dad', '▁was', '▁laid', '▁off', '▁from', '▁the', '▁job', '▁he', 'd', '▁held', '▁for', '▁over', '▁a', '▁decade', 'he', '▁has', '▁clung', '▁to', '▁a', '▁sliver', '▁of', '▁hope', '▁that', '▁his', '▁father', '▁might', '▁one', '▁day', '▁apologize', '▁and', '▁offer', '▁an', '▁excuse', '▁about', '▁having', '▁important', '▁work', '▁to', '▁take', '▁care', '▁of', '▁instead', '▁of', '▁showing', '▁up', '▁', 'i', '▁just', '▁want', '▁dad', '▁to', '▁come', '▁up', '▁to', '▁me', '▁before', '▁a', '▁game', '▁put', '▁his', '▁hand', '▁on', '▁my', '▁shoulder', '▁and', '▁finally', '▁say', '▁im', '▁not', '▁going', '▁to', '▁be', '▁there', '▁tonight', '▁champ', '▁said', '▁the', '▁second', '▁baseman', '▁for', '▁the', '▁leagues', '▁blue', '▁', 'jay', 's', '▁club', '▁if', '▁he', '▁only', '▁knew', '▁how', '▁much', '▁', 'i', '▁think', '▁about', '▁walking', '▁off', '▁the', '▁field', '▁after', '▁a', '▁game', '▁without', '▁being', '▁hugged', '▁or', '▁congratulated', '▁that', 's', '▁all', '▁', 'i', '▁want', '▁ultimately', '▁', 'gar', 'r', 'ett', '▁said', '▁that', '▁when', '▁he', '▁later', '▁looks', '▁back', '▁at', '▁this', '▁time', '▁in', '▁his', '▁life', '▁he', '▁wants', '▁to', '▁remember', '▁his', '▁father', '▁having', '▁work', '▁obligations', '▁that', '▁prevented', '▁him', '▁from', '▁attending', '▁his', '▁sons', '▁extra', 'curricular', '▁activities', '▁', 'i', '▁just', '▁wish', '▁dad', '▁would', '▁realize', '▁how', '▁much', '▁it', '▁means', '▁to', '▁me', '▁that', '▁he', '▁not', '▁be', '▁here', '▁said', '▁', 'gar', 'r', 'ett', '▁before', '▁taking', '▁the', '▁field', '▁when', '▁it', '▁comes', '▁down', '▁to', '▁it', '▁', 'i', '▁just', '▁want', '▁my', '▁dad', '▁to', '▁have', '▁a', '▁little', '▁less', '▁time', '▁for', '▁me', '▁you', '▁know', '▁the', '▁10', 'year', 'old', '▁then', '▁reportedly', '▁covered', '▁the', '▁tears', '▁well', 'ing', '▁in', '▁his', '▁eyes', '▁with', '▁his', '▁glove', '▁after', '▁hearing', '▁the', '▁phrase', '▁go', '▁get', '▁em', '▁', 'nate', '▁shouted', '▁from', '▁behind', '▁the', '▁dugout', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']'], ['▁sports', '▁journalists', '▁and', '▁television', '▁crews', '▁were', '▁pushed', '▁aside', '▁during', '▁super', '▁bowl', '▁media', '▁day', '▁on', '▁', 'tu', 'es', 'day', '▁as', '▁more', '▁than', '▁1000', '▁writers', '▁for', '▁the', '▁website', '▁bleach', 'er', 'report', 'com', '▁entered', '▁', 'luc', 'as', '▁oil', '▁stadium', '▁to', '▁acquire', '▁material', '▁for', '▁their', '▁trademark', '▁style', '▁of', '▁report', 'age', '▁', 'i', '▁asked', '▁to', 'm', '▁bar', 'dy', '▁', 's', 'ic', '▁where', '▁he', '▁thought', '▁he', '▁should', '▁be', '▁on', '▁my', '▁list', '▁of', '▁the', '▁top', '▁10', '▁guys', '▁to', '▁ever', '▁play', '▁in', '▁the', '▁super', '▁bowl', '▁and', '▁he', '▁said', '▁it', '▁didn', 't', '▁sound', '▁like', '▁', 'i', '▁had', '▁anyone', '▁who', '▁played', '▁before', '▁2005', '▁said', '▁bleach', 'er', '▁report', '▁writer', '▁', 'dar', 'ron', '▁nasty', '▁16', '▁whose', '▁credentials', '▁identified', '▁him', '▁as', '▁writer', '▁top', '▁10', '▁', 'carolina', '▁and', '▁', 'miami', '▁hurricane', 's', '▁writer', '▁', 'jun', 'e', '▁2011', '▁', 'i', '▁think', '▁we', '▁got', '▁a', '▁lot', '▁of', '▁good', '▁answers', '▁though', '▁and', '▁our', '▁super', '▁bowl', '▁analysis', '▁lists', '▁are', '▁going', '▁to', '▁give', '▁a', '▁lot', '▁of', '▁insight', '▁to', '▁the', '▁fans', '▁and', '▁coaching', '▁staff', 's', '▁also', '▁at', '▁media', '▁day', '▁for', '▁the', '▁first', '▁time', '▁was', '▁the', '▁sports', '▁and', '▁culture', '▁web', '▁magazine', '▁grant', 'land', '▁which', '▁sent', '▁', 'vin', '▁', 's', 'cul', 'ly', '▁to', '▁', 'nar', 'rate', '▁the', '▁proceedings', '▁so', '▁that', '▁editors', '▁could', '▁sit', '▁at', '▁home', '▁listening', '▁to', '▁him', '▁on', '▁the', '▁radio', '▁while', '▁drinking', '▁', 'cog', 'nac', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']'], ['▁', 'salem', '▁', 'va', 'for', '▁the', '▁eighth', '▁straight', '▁world', 'history', '▁period', '▁sophomore', 's', '▁at', '▁', 'riverside', '▁high', '▁school', '▁watched', '▁the', '▁1959', '▁classic', '▁', 'ben', 'hur', '▁', 'tu', 'es', 'day', '▁the', '▁chariot', '▁races', '▁were', '▁pretty', '▁cool', '▁mi', 'cha', 'el', '▁bow', 'er', '▁said', '▁of', '▁the', '▁21', '1', 'minute', '▁film', '▁he', '▁and', '▁classmates', '▁have', '▁been', '▁watching', '▁in', '▁25', 'minute', '▁segments', '▁between', '▁roll', '▁call', '▁and', '▁free', 'reading', '▁and', '▁when', '▁', 'm', 'r', '▁frank', 's', '▁got', '▁back', '▁from', '▁the', '▁teachers', '▁lounge', '▁he', '▁told', '▁us', '▁', 'je', 's', 'us', '▁is', '▁in', '▁tomorrow', 's', '▁part', '▁bow', 'er', '▁said', '▁he', '▁dread', 's', '▁next', '▁week', '▁when', '▁the', '▁class', '▁will', '▁break', '▁into', '▁', 'ben', 'hur', '▁discussion', '▁groups', '▁and', '▁share', '▁their', '▁ancient', 'history', '▁unit', '▁journals', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']']]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
        "tokenized_texts = []\n",
        "for sent in list(sentences):\n",
        "  x = tokenizer.tokenize(sent)\n",
        "  tokenized_texts.append(x)\n",
        "print(tokenized_texts[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Cp9BPRd1tMIo"
      },
      "outputs": [],
      "source": [
        "# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n",
        "MAX_LEN = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mFhowDMohU4H"
      },
      "outputs": [],
      "source": [
        "# Use the XLNet tokenizer to convert the tokens to their index numbers in the XLNet vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kDs-MYtYH8sL"
      },
      "outputs": [],
      "source": [
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cDoC24LeEv3N"
      },
      "outputs": [],
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "aFbE-UHvsb7-"
      },
      "outputs": [],
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jw5K2A5Ko1RF"
      },
      "outputs": [],
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GEgLpFVlo1Z-"
      },
      "outputs": [],
      "source": [
        "# Select a batch size for training. For fine-tuning with XLNet, the authors recommend a batch size of 32, 48, or 128. We will use 32 here to avoid memory issues.\n",
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659,
          "referenced_widgets": [
            "5ce26babb9fb4d4e806168863f449bee",
            "ea62bbda8ec84b1bbffebeca050d3a6c",
            "2218ace88a9f4464bab1886623052564",
            "2a75fcdafdb3430c9c90298817c85753",
            "370c479d0c3544b3b4e6dba6cef2bed2",
            "7735a34c6f47498b9089b8323fcfb4f1",
            "60f15c5b001645cf934cb3cddd7bb9b9",
            "d65f05a06280492db55982364fe2557b",
            "010fe8fd2e9d47e6b3804082429ab0d6",
            "cc2073e7d1524fb1996c897764d86973",
            "63e8f2a50860425c82215b8aa2569b48"
          ]
        },
        "id": "gFsCTp_mporB",
        "outputId": "26952bc3-0a93-4799-d3eb-5e6242cae80a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ce26babb9fb4d4e806168863f449bee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
            "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForSequenceClassification(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (sequence_summary): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "    (first_dropout): Identity()\n",
              "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (logits_proj): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Load XLNEtForSequenceClassification, the pretrained XLNet model with a single linear classification layer on top. \n",
        "\n",
        "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=4)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QxSMw0FrptiL"
      },
      "outputs": [],
      "source": [
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLs72DuMODJO",
        "outputId": "415327d4-3009-4b33-f31f-65d4b36ed2a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                     lr=2e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J-FYdx6nFE_",
        "outputId": "529fe2d4-17ab-439d-ba3d-426c38c45471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.15452618579250751\n"
          ]
        }
      ],
      "source": [
        "out = []\n",
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "  \n",
        "# Training\n",
        "\n",
        "# Set our model to training mode (as opposed to evaluation mode)\n",
        "model.train()\n",
        "\n",
        "# Tracking variables\n",
        "tr_loss = 0\n",
        "nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "# Train the data for one epoch\n",
        "for step, batch in enumerate(train_dataloader):\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  # Clear out the gradients (by default they accumulate)\n",
        "  optimizer.zero_grad()\n",
        "  # Forward pass\n",
        "  outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "  loss = outputs[0]\n",
        "  logits = outputs[1]\n",
        "  train_loss_set.append(loss.item())    \n",
        "  # Backward pass\n",
        "  loss.backward()\n",
        "  # Update parameters and take a step using the computed gradient\n",
        "  optimizer.step()\n",
        "  \n",
        "  \n",
        "  # Update tracking variables\n",
        "  tr_loss += loss.item()\n",
        "  nb_tr_examples += b_input_ids.size(0)\n",
        "  nb_tr_steps += 1\n",
        "\n",
        "print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation\n",
        "\n",
        "# Put model in evaluation mode to evaluate loss on the validation set\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "eval_f1 = 0\n",
        "\n",
        "tp = [0, 0, 0, 0]\n",
        "fp = [0, 0, 0, 0]\n",
        "fn = [0, 0, 0, 0]\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in validation_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "  with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    logits = output[0]\n",
        "  \n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "  # tmp_f1 = flat_f1(logits, label_ids)\n",
        "  \n",
        "  eval_accuracy += tmp_eval_accuracy\n",
        "  # eval_f1 += tmp_f1\n",
        "  nb_eval_steps += 1\n",
        "\n",
        "  pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "  labels_flat = label_ids.flatten()\n",
        "  for i in range(4):\n",
        "      ai = [i] * len(labels_flat)\n",
        "      fp[i] += np.sum((pred_flat != labels_flat) & (pred_flat == ai))\n",
        "      tp[i] += np.sum((pred_flat == labels_flat) & (pred_flat == ai))\n",
        "      fn[i] += np.sum((pred_flat != labels_flat) & (labels_flat == ai))\n",
        "\n",
        "f1_total = 0\n",
        "for i in range(4):\n",
        "  if tp[i] == 0:\n",
        "    print(\"0 tp -\", i)\n",
        "    continue\n",
        "\n",
        "  p = tp[i] / (tp[i] + fp[i])\n",
        "  r = tp[i] / (tp[i] + fn[i])\n",
        "  f1_total += 2*(p * r) / (p + r)\n",
        "  \n",
        "print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Validation Macro F1: {}\".format(f1_total/4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fd0mt2FPEnu",
        "outputId": "3a49d79e-a840-4832-ad75-db30f03d4a3b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9771241830065359\n",
            "Validation Macro F1: 0.9747002085552463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts = test_df.text.values\n",
        "test_labels = test_df.label.values - 1\n",
        "test_sentences = preprocess_text(test_texts)\n",
        "test_tokenized_texts = []\n",
        "for sent in list(test_sentences):\n",
        "  x = tokenizer.tokenize(sent)\n",
        "  test_tokenized_texts.append(x)\n",
        "\n",
        "test_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in test_tokenized_texts]\n",
        "test_input_ids = pad_sequences(test_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "test_attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in test_input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  test_attention_masks.append(seq_mask)\n",
        "\n",
        "# _, test_validation_inputs, _, test_validation_labels = train_test_split(test_input_ids, test_labels, \n",
        "#                                                             random_state=2018, test_size=1)\n",
        "# _, test_validation_masks, _, _ = train_test_split(test_attention_masks, test_input_ids,\n",
        "#                                              random_state=2018, test_size=1)\n",
        "\n",
        "test_validation_inputs = torch.tensor(test_input_ids)\n",
        "test_validation_labels = torch.tensor(test_labels)\n",
        "test_validation_masks = torch.tensor(test_attention_masks)\n",
        "test_validation_data = TensorDataset(test_validation_inputs, test_validation_masks, test_validation_labels)\n",
        "test_validation_sampler = SequentialSampler(test_validation_data)\n",
        "test_validation_dataloader = DataLoader(test_validation_data, sampler=test_validation_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "YFiQBjL_9tVq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYUdsSOZUpHB",
        "outputId": "da4154bd-8cc9-4e4c-f256-0a1d6dc3c1c9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForSequenceClassification(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (sequence_summary): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "    (first_dropout): Identity()\n",
              "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (logits_proj): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(test_validation_inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xuFqerKU5zw",
        "outputId": "4e2cffbe-a190-45ed-9183-e9f2658e7918"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "tp = [0, 0, 0, 0]\n",
        "fp = [0, 0, 0, 0]\n",
        "fn = [0, 0, 0, 0]\n",
        "\n",
        "\n",
        "for batch in test_validation_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "  with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    logits = output[0]\n",
        "  \n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "  \n",
        "  eval_accuracy += tmp_eval_accuracy\n",
        "  nb_eval_steps += 1\n",
        "\n",
        "  pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "  labels_flat = label_ids.flatten()\n",
        "  for i in range(4):\n",
        "      ai = [i] * len(labels_flat)\n",
        "      fp[i] += np.sum((pred_flat != labels_flat) & (pred_flat == ai))\n",
        "      tp[i] += np.sum((pred_flat == labels_flat) & (pred_flat == ai))\n",
        "      fn[i] += np.sum((pred_flat != labels_flat) & (labels_flat == ai))\n",
        "\n",
        "f1_total = 0\n",
        "for i in range(4):\n",
        "  if tp[i] == 0:\n",
        "    print(\"0 tp -\", i)\n",
        "    continue\n",
        "\n",
        "  p = tp[i] / (tp[i] + fp[i])\n",
        "  r = tp[i] / (tp[i] + fn[i])\n",
        "  f1_total += 2*(p * r) / (p + r)\n",
        "  \n",
        "print(\"Test Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Test Validation Macro F1: {}\".format(f1_total/4))"
      ],
      "metadata": {
        "id": "eVaIDW25_CdE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1353af10f04149fe83f1018fde062698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b5ef3cb0b7e46acaedcf7caca19d556",
              "IPY_MODEL_f3b486baa27c4471baeab76c32df917a",
              "IPY_MODEL_442d379dbc824f7dadf9c53c04472b23"
            ],
            "layout": "IPY_MODEL_87995a7c3eed4b4aae3a7af2ebd7ac6a"
          }
        },
        "0b5ef3cb0b7e46acaedcf7caca19d556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0316cc21d5c4f2280bc23432f490ce5",
            "placeholder": "​",
            "style": "IPY_MODEL_5b33bdab017e45ceaa3592927ed8ce73",
            "value": "Downloading (…)ve/main/spiece.model: 100%"
          }
        },
        "f3b486baa27c4471baeab76c32df917a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5ede80fb34d49b1ad00d2d1842088f9",
            "max": 798011,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47b93244df814febad88e637eb9d5eed",
            "value": 798011
          }
        },
        "442d379dbc824f7dadf9c53c04472b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95b09ebe4f67437dafa1117aa5cfd1e2",
            "placeholder": "​",
            "style": "IPY_MODEL_49470edcc9f7419db24ef543fadf1975",
            "value": " 798k/798k [00:00&lt;00:00, 5.50MB/s]"
          }
        },
        "87995a7c3eed4b4aae3a7af2ebd7ac6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0316cc21d5c4f2280bc23432f490ce5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b33bdab017e45ceaa3592927ed8ce73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5ede80fb34d49b1ad00d2d1842088f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47b93244df814febad88e637eb9d5eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95b09ebe4f67437dafa1117aa5cfd1e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49470edcc9f7419db24ef543fadf1975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dc20ba835f0474f88ac866e475b31fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5009870fd35b4528a7684aabce838da5",
              "IPY_MODEL_ca83883a5f2b4c139703f467f8afd854",
              "IPY_MODEL_de8ad2bdfef84fa4bfa70abe41bb75f8"
            ],
            "layout": "IPY_MODEL_e0ad402adb3c48348a76af36606919c2"
          }
        },
        "5009870fd35b4528a7684aabce838da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9494cfba2684f6da25093fdfe0dbe7f",
            "placeholder": "​",
            "style": "IPY_MODEL_ed3a0593affe4af48cf7eb665cf01acb",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "ca83883a5f2b4c139703f467f8afd854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5abe428effd348978d03727a5967ee1c",
            "max": 760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee8e066a69f24fa6b6526504d5e00795",
            "value": 760
          }
        },
        "de8ad2bdfef84fa4bfa70abe41bb75f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38718a243c9d4c2cb94346b30f247bfe",
            "placeholder": "​",
            "style": "IPY_MODEL_880191661a7941749eafed833e3a3238",
            "value": " 760/760 [00:00&lt;00:00, 14.8kB/s]"
          }
        },
        "e0ad402adb3c48348a76af36606919c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9494cfba2684f6da25093fdfe0dbe7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed3a0593affe4af48cf7eb665cf01acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5abe428effd348978d03727a5967ee1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee8e066a69f24fa6b6526504d5e00795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38718a243c9d4c2cb94346b30f247bfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "880191661a7941749eafed833e3a3238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ce26babb9fb4d4e806168863f449bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea62bbda8ec84b1bbffebeca050d3a6c",
              "IPY_MODEL_2218ace88a9f4464bab1886623052564",
              "IPY_MODEL_2a75fcdafdb3430c9c90298817c85753"
            ],
            "layout": "IPY_MODEL_370c479d0c3544b3b4e6dba6cef2bed2"
          }
        },
        "ea62bbda8ec84b1bbffebeca050d3a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7735a34c6f47498b9089b8323fcfb4f1",
            "placeholder": "​",
            "style": "IPY_MODEL_60f15c5b001645cf934cb3cddd7bb9b9",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "2218ace88a9f4464bab1886623052564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d65f05a06280492db55982364fe2557b",
            "max": 467042463,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_010fe8fd2e9d47e6b3804082429ab0d6",
            "value": 467042463
          }
        },
        "2a75fcdafdb3430c9c90298817c85753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc2073e7d1524fb1996c897764d86973",
            "placeholder": "​",
            "style": "IPY_MODEL_63e8f2a50860425c82215b8aa2569b48",
            "value": " 467M/467M [00:20&lt;00:00, 24.5MB/s]"
          }
        },
        "370c479d0c3544b3b4e6dba6cef2bed2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7735a34c6f47498b9089b8323fcfb4f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60f15c5b001645cf934cb3cddd7bb9b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d65f05a06280492db55982364fe2557b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "010fe8fd2e9d47e6b3804082429ab0d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc2073e7d1524fb1996c897764d86973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63e8f2a50860425c82215b8aa2569b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}